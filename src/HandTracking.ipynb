{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BluBloos/3D-Hand-Tracking/blob/main/src/HandTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytgQcZUUwswL"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c_ZBgm__TNlq",
        "outputId": "0243a5f4-6429-406f-b96e-346c50e1543d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing github repository\n",
            "total 56\n",
            "drwxr-xr-x 1 root root 4096 Mar 31 22:38 .\n",
            "drwxr-xr-x 1 root root 4096 Mar 31 21:50 ..\n",
            "drwxr-xr-x 1 root root    0 Mar 31 22:41 data\n",
            "drwxr-xr-x 8 root root 4096 Mar 31 22:38 .git\n",
            "-rw-r--r-- 1 root root  172 Mar 31 21:57 .gitignore\n",
            "drwxr-xr-x 3 root root 4096 Mar 31 21:57 MessyCloset\n",
            "drwxr-xr-x 2 root root 4096 Mar 31 21:57 paper\n",
            "-rw-r--r-- 1 root root 2308 Mar 31 21:57 README.md\n",
            "drwxr-xr-x 4 root root 4096 Mar 31 21:57 RHD_small\n",
            "-rwxr-xr-x 1 root root   30 Mar 31 21:57 run.sh\n",
            "drwxr-xr-x 4 root root 4096 Mar 31 21:57 src\n",
            "-rw-r--r-- 1 root root 4460 Mar 31 21:57 TODO.md\n",
            "drwxr-xr-x 2 root root 4096 Mar 31 21:57 .vscode\n",
            "rm: cannot remove '.config/': No such file or directory\n",
            "rm: cannot remove 'sample_data/': No such file or directory\n",
            "fatal: destination path '.' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# RUN THIS BLOCK ONLY WHEN IN COLAB\n",
        "\n",
        "!echo \"Initializing github repository\"\n",
        "!ls -la\n",
        "!rm -r .config/\n",
        "!rm -r sample_data/\n",
        "!git clone https://github.com/BluBloos/QMIND2021-2022/ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ee72KKdTPIsZ",
        "outputId": "e87c3cf0-8d17-4a04-944a-039c54a7b85a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/BluBloos/QMIND2021-2022\n",
            "   b35791d..5cfb611  main       -> origin/main\n",
            "Updating b35791d..5cfb611\n",
            "Fast-forward\n",
            " src/HandTracking.ipynb | 1827 \u001b[32m++\u001b[m\u001b[31m----------------------------------------------\u001b[m\n",
            " 1 file changed, 73 insertions(+), 1754 deletions(-)\n",
            "In Colab: True\n",
            "Not connected to a GPU\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "You are using a high-RAM runtime!\n",
            "TensorFlow version: 2.8.0\n",
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from chumpy) (1.4.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from chumpy) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.13.0->chumpy) (1.21.5)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58285 sha256=f156f71c82f580b05019091faef3a5291f761c009007a8a6962338b97f972a05\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/68/de/5e0c5d77e573e8c150e69e07a25035e6b6a04952d6e1814dbc\n",
            "Successfully built chumpy\n",
            "Installing collected packages: chumpy\n",
            "Successfully installed chumpy-0.70\n"
          ]
        }
      ],
      "source": [
        "# ALWAYS RUN THIS BLOCK, COLAB OR NOT\n",
        "\n",
        "# Download updated project from Github.\n",
        "!git pull\n",
        "\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "print(\"In Colab:\", IN_COLAB)\n",
        "import sys\n",
        "if (IN_COLAB):\n",
        "  sys.path.insert(1, '/content/src/')\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "#NOTE: Good resource. -> https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "import cv2 # opencv, for image resizing.\n",
        "!pip install chumpy\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "\n",
        "############## HELPER FUNCTIONS ############## \n",
        "# NOTE(Noah): Stole this function from Stackoverflow :)\n",
        "def rgb2gray(rgb):\n",
        "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=2)\n",
        "def resize(img, size):\n",
        "    return cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "############## HELPER FUNCTIONS ############## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pebm8lODx0fu"
      },
      "source": [
        "# DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7SDaXTQZuF0y",
        "outputId": "ebdcd17b-2536-4a41-c219-05d75b8298ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://packages.cloud.google.com/apt gcsfuse-bionic main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2537  100  2537    0     0   117k      0 --:--:-- --:--:-- --:--:--  117k\n",
            "OK\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Release [3,089 B]\n",
            "Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Release.gpg [488 B]\n",
            "Fetched 3,577 B in 1s (3,573 B/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.40.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 82 not upgraded.\n",
            "2022/03/31 22:45:03.739017 Start gcsfuse/0.40.0 (Go version go1.17.6) for app \"\" using mount point: /content/data\n",
            "2022/03/31 22:45:03.783687 Opening GCS connection...\n",
            "2022/03/31 22:45:04.221564 Mounting file system \"shd_final\"...\n",
            "2022/03/31 22:45:04.224514 File system has been successfully mounted.\n"
          ]
        }
      ],
      "source": [
        "from matplotlib.image import imread\n",
        "\n",
        "# NOTE(Noah): gcs code will on work on the colab as this code is Ubuntu specific.\n",
        "# I attempted to install gcsfuse on my macOS machine, but I have a version that is too new.\n",
        "# also, gcsfuse simply does not work on Windows.\n",
        "#\n",
        "# gcsfuse is actually beta software.\n",
        "if IN_COLAB:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # we know that we are on an Ubuntu machine.\n",
        "  # Thus, installing gcsfuse will be done via the Ubuntu instructions.\n",
        "  # https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/installing.md#ubuntu-and-debian-latest-releases\n",
        "  !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "  !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "  \n",
        "  # -y in apt-get will assume \"yes\" as the answer to all prompts.\n",
        "  # -q in apt-get will make things \"quiet\" for us. Nice!\n",
        "  !sudo apt-get -y -q update\n",
        "  !sudo apt-get -y -q install gcsfuse\n",
        "\n",
        "  !mkdir -p data\n",
        "  !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 shd_final data\n",
        "\n",
        "def download_image(path):\n",
        "  image = imageio.imread(path)\n",
        "  _image = image.astype('float32')\n",
        "  if GRAYSCALE:\n",
        "      _image = rgb2gray(_image / 255)\n",
        "  else:\n",
        "      _image = _image / 255\n",
        "  _image = resize(_image, IMAGE_SIZE)\n",
        "  return _image\n",
        "\n",
        "# TODO(Noah): Reimplement the code that sets up SH_RHD.\n",
        "gcs_path = 'data' if IN_COLAB else os.path.join(\"..\", \"SH_RHD\")\n",
        "train_list = os.listdir(os.path.join(gcs_path, \"training/color\"))\n",
        "eval_list = os.listdir(os.path.join(gcs_path, \"evaluation/color\"))\n",
        "\n",
        "# Setup some params.\n",
        "IMAGE_SIZE = 224\n",
        "GRAYSCALE = False\n",
        "IMAGE_CHANNELS = 1 if GRAYSCALE else 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "# numpy \"buckets\" that we will use to load things in.\n",
        "x_train = np.zeros( (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) )\n",
        "y_train = np.zeros( (BATCH_SIZE, 21, 3) )\n",
        "x_test = np.zeros( (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) ) \n",
        "y_test = np.zeros( (BATCH_SIZE, 21, 3) )\n",
        "TRAIN_IMAGES = (len(train_list) // BATCH_SIZE) * BATCH_SIZE\n",
        "TEST_IMAGES = (len(eval_list) // BATCH_SIZE) * BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.arrayprint import array_str\n",
        "\n",
        "anno_train_path = '/content/data/anno/anno_training.pickle'\n",
        "anno_eval_path = '/content/data/anno/anno_evaluation.pickle'\n",
        "\n",
        "\n",
        "\n",
        "def load_anno(path, arr):\n",
        "  anno_all = []\n",
        "  count = 0\n",
        "  with open(path, 'rb') as f:\n",
        "    anno_all = pickle.load(f)\n",
        "\n",
        "  for key, value in anno_all.items():\n",
        "    if(count>BATCH_SIZE):\n",
        "      break\n",
        "    kp_visible = (value['uv_vis'][:, 2] == 1)\n",
        "    case1 = np.sum(kp_visible[0:21])\n",
        "    case2 = np.sum(kp_visible[21:])\n",
        "    valid_case = (case1 > 0 and case2 == 0) or (case1 == 0 and case2 > 0) \n",
        "    if(valid_case):\n",
        "      if(case1 ==0):\n",
        "        arr[count,:,:]= value['xyz'][21:42]\n",
        "        count+=1\n",
        "      if(case2 == 0):\n",
        "        arr[count,:,:]= value['xyz'][:21]\n",
        "        count+=1\n",
        "\n",
        "\n",
        "load_anno(anno_train_path, y_test)\n",
        "load_anno(anno_eval_path, y_train)\n",
        "print(y_test)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "EMJu2pBWKJx8",
        "outputId": "43fda7da-6a8a-4a3c-d143-67068749b89e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.05232     0.04117     0.50650001]\n",
            "  [-0.0145      0.05161     0.38370001]\n",
            "  [-0.02626     0.03721     0.4012    ]\n",
            "  ...\n",
            "  [-0.03639     0.1207      0.44679999]\n",
            "  [-0.02022     0.124       0.44850001]\n",
            "  [-0.01898     0.1031      0.46970001]]\n",
            "\n",
            " [[ 0.01842    -0.1045      0.36899999]\n",
            "  [-0.03311    -0.03275     0.4533    ]\n",
            "  [-0.02735    -0.04798     0.43669999]\n",
            "  ...\n",
            "  [ 0.03712     0.001316    0.41170001]\n",
            "  [ 0.03799    -0.01236     0.40369999]\n",
            "  [ 0.03472    -0.03851     0.40130001]]\n",
            "\n",
            " [[ 0.06759    -0.2158      0.57309997]\n",
            "  [ 0.09856     0.003095    0.50629997]\n",
            "  [ 0.1105     -0.06151     0.51679999]\n",
            "  ...\n",
            "  [-0.007587   -0.01352     0.52329999]\n",
            "  [-0.009917   -0.03699     0.54650003]\n",
            "  [-0.005691   -0.09856     0.56379998]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.07942     0.05822     0.3971    ]\n",
            "  [-0.06131     0.05076     0.39039999]\n",
            "  [-0.02952     0.05302     0.3863    ]\n",
            "  ...\n",
            "  [-0.04179     0.03308     0.45429999]\n",
            "  [-0.02578     0.02308     0.44850001]\n",
            "  [ 0.00719     0.01256     0.4413    ]]\n",
            "\n",
            " [[ 0.1036      0.01656     0.63380003]\n",
            "  [ 0.03978    -0.1227      0.45089999]\n",
            "  [ 0.075      -0.08906     0.49649999]\n",
            "  ...\n",
            "  [ 0.08978     0.07787     0.53570002]\n",
            "  [ 0.07977     0.076       0.5043    ]\n",
            "  [ 0.02384     0.07259     0.53530002]]\n",
            "\n",
            " [[ 0.004709    0.07363     0.52530003]\n",
            "  [ 0.08624     0.03095     0.4474    ]\n",
            "  [ 0.07822     0.04077     0.46759999]\n",
            "  ...\n",
            "  [ 0.07284     0.1332      0.4578    ]\n",
            "  [ 0.06018     0.1251      0.45210001]\n",
            "  [ 0.03736     0.1087      0.46329999]]]\n",
            "[[[-0.00488    -0.05724     0.70179999]\n",
            "  [-0.01406     0.03035     0.58289999]\n",
            "  [-0.02056     0.01356     0.6067    ]\n",
            "  ...\n",
            "  [ 0.06011     0.03241     0.60360003]\n",
            "  [ 0.05921     0.01552     0.61009997]\n",
            "  [ 0.04836    -0.01112     0.639     ]]\n",
            "\n",
            " [[ 0.001013   -0.15279999  0.46079999]\n",
            "  [ 0.0473     -0.04534     0.42179999]\n",
            "  [ 0.04475    -0.06748     0.4251    ]\n",
            "  ...\n",
            "  [-0.03373    -0.06167     0.44220001]\n",
            "  [-0.02851    -0.05696     0.45840001]\n",
            "  [-0.01743    -0.07671     0.4727    ]]\n",
            "\n",
            " [[-0.05453    -0.002965    0.61909997]\n",
            "  [-0.1182      0.1114      0.54909998]\n",
            "  [-0.1042      0.08703     0.55930001]\n",
            "  ...\n",
            "  [-0.08566     0.08741     0.63980001]\n",
            "  [-0.08044     0.1043      0.63590002]\n",
            "  [-0.04911     0.09109     0.61339998]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.02147     0.05506     0.58410001]\n",
            "  [ 0.03552     0.02392     0.4707    ]\n",
            "  [ 0.03038     0.01806     0.49180001]\n",
            "  ...\n",
            "  [ 0.02872     0.09128     0.48859999]\n",
            "  [ 0.04587     0.09122     0.49259999]\n",
            "  [ 0.05312     0.08326     0.51719999]]\n",
            "\n",
            " [[-0.002347   -0.07026     0.48069999]\n",
            "  [ 0.06148    -0.1026      0.37830001]\n",
            "  [ 0.05588    -0.09722     0.40220001]\n",
            "  ...\n",
            "  [ 0.02282    -0.02764     0.4206    ]\n",
            "  [ 0.01307    -0.01947     0.41049999]\n",
            "  [-0.008193   -0.02259     0.42399999]]\n",
            "\n",
            " [[-0.04204    -0.1481      0.57789999]\n",
            "  [ 0.03032    -0.04238     0.50910002]\n",
            "  [ 0.02376    -0.07005     0.50959998]\n",
            "  ...\n",
            "  [-0.001842   -0.04777     0.55599999]\n",
            "  [-0.01604    -0.04124     0.56169999]\n",
            "  [-0.0371     -0.0549      0.59149998]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSW4BpvZPIsb"
      },
      "source": [
        "# MODEL LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JLws7Z0QPIsb",
        "outputId": "9a7b0ee8-7b78-4acd-8264-ab7f74789b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fd386c5a8406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmobilehand_lfuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOSS_3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mMOBILE_HAND\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAKE_MOBILE_HAND\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_CHANNELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMANO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# INTEGRATION TEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/src/mobilehand.py\u001b[0m in \u001b[0;36mMAKE_MOBILE_HAND\u001b[0;34m(image_size, image_channels, batch_size, mano_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mmobile_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAKE_MOBILE_NET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mreg_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAKE_REGRESSION_MODULE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmano_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMANO_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmano_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/src/mobilenet_layer.py\u001b[0m in \u001b[0;36mMAKE_MOBILE_NET\u001b[0;34m(image_size, image_channels)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# tensorflow appends increasing numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# to the model names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mmobileNetOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobileNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'global_average_pooling2d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       raise ValueError(f'No such layer: {name}. Existing layers are: '\n\u001b[0m\u001b[1;32m   2829\u001b[0m                        f'{list(layer.name for layer in self.layers)}.')\n\u001b[1;32m   2830\u001b[0m     raise ValueError('Provide either a layer name or layer index at '\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: global_average_pooling2d. Existing layers are: ['input_8', 'rescaling_1', 'Conv', 'Conv/BatchNorm', 'tf.__operators__.add_28', 're_lu_33', 'tf.math.multiply_28', 'multiply_19', 'expanded_conv/depthwise/pad', 'expanded_conv/depthwise', 'expanded_conv/depthwise/BatchNorm', 're_lu_34', 'expanded_conv/squeeze_excite/AvgPool', 'expanded_conv/squeeze_excite/Conv', 'expanded_conv/squeeze_excite/Relu', 'expanded_conv/squeeze_excite/Conv_1', 'tf.__operators__.add_29', 're_lu_35', 'tf.math.multiply_29', 'expanded_conv/squeeze_excite/Mul', 'expanded_conv/project', 'expanded_conv/project/BatchNorm', 'expanded_conv_1/expand', 'expanded_conv_1/expand/BatchNorm', 're_lu_36', 'expanded_conv_1/depthwise/pad', 'expanded_conv_1/depthwise', 'expanded_conv_1/depthwise/BatchNorm', 're_lu_37', 'expanded_conv_1/project', 'expanded_conv_1/project/BatchNorm', 'expanded_conv_2/expand', 'expanded_conv_2/expand/BatchNorm', 're_lu_38', 'expanded_conv_2/depthwise', 'expanded_conv_2/depthwise/BatchNorm', 're_lu_39', 'expanded_conv_2/project', 'expanded_conv_2/project/BatchNorm', 'expanded_conv_2/Add', 'expanded_conv_3/expand', 'expanded_conv_3/expand/BatchNorm', 'tf.__operators__.add_30', 're_lu_40', 'tf.math.multiply_30', 'multiply_20', 'expanded_conv_3/depthwise/pad', 'expanded_conv_3/depthwise', 'expanded_conv_3/depthwise/BatchNorm', 'tf.__operators__.add_31', 're_lu_41', 'tf.math.multiply_31', 'multiply_21', 'expanded_conv_3/squeeze_excite/AvgPool', 'expanded_con..."
          ]
        }
      ],
      "source": [
        "# TODO(Noah): Get the MANO folders hosted in GCS so that this works again.\n",
        "#   We note that this cost was tested and is in full working order, so \n",
        "#   the only thing not working is the lack of existence of MANO_DIR. \n",
        "\n",
        "MANO_DIR = os.path.join(\"data\", \"mano_v1_2\") if IN_COLAB else os.path.join(\"..\", \"mano_v1_2\")\n",
        "\n",
        "from mobilehand import MAKE_MOBILE_HAND\n",
        "from mobilehand_lfuncs import LOSS_3D\n",
        "\n",
        "MOBILE_HAND = MAKE_MOBILE_HAND(IMAGE_SIZE, IMAGE_CHANNELS, BATCH_SIZE, MANO_DIR)\n",
        "\n",
        "# INTEGRATION TEST\n",
        "input_test = tf.random.uniform(shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
        "input_test = tf.cast(input_test, tf.float32)\n",
        "output_test = MOBILE_HAND(input_test)\n",
        "print(output_test)\n",
        "\n",
        "# The lower training loop assumes that the model is set as such.\n",
        "model = MOBILE_HAND\n",
        "\n",
        "# The lower training loop also assumes that we have the loss function set like so.\n",
        "loss_fn = lambda pred, gt : LOSS_3D(pred,gt) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3xZXThyyVta"
      },
      "source": [
        "# TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpOZpsk5rNev"
      },
      "outputs": [],
      "source": [
        "class StupidSimpleLossMetric():\n",
        "    def __init__(self):\n",
        "        self.losses = [] # empty python array \n",
        "    def __call__(self, loss):\n",
        "        self.losses.append(loss)\n",
        "    def result(self):\n",
        "        return sum(self.losses) / len(self.losses)\n",
        "    def reset_states(self):\n",
        "        self.losses = []\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # defaults should work just fine\n",
        "train_loss = StupidSimpleLossMetric()\n",
        "test_loss = StupidSimpleLossMetric()\n",
        "\n",
        "# Loss function unit test\n",
        "input = tf.zeros([1, 21,3])  # mock pred of all zeros\n",
        "label = np.expand_dims(y_train[0], axis=0)\n",
        "loss = loss_fn(input, label) \n",
        "print('Loss for pred of all zeros', loss.numpy())\n",
        "#loss2 = loss_fn(label, label)\n",
        "#print('Loss for perfect prediction', loss2.numpy())\n",
        "input2 = tf.ones([1, 21, 3])\n",
        "loss3 = loss_fn(input2, label)\n",
        "print('Loss for pred of all ones', loss3.numpy())\n",
        "\n",
        "@tf.function\n",
        "def train_step(input, gt):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(input)\n",
        "        #loss = loss_func(predictions, segmentation_masks)\n",
        "        #loss = np.dot(tf.reshape(segmentation_masks, [102400], tf.reshape(predictions, [102400])\n",
        "        loss = loss_fn(predictions, gt)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "    #train_accuracy(labels, predictions)\n",
        "  \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  return loss_fn(predictions, labels)\n",
        "  #test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZawQmCPIsf"
      },
      "outputs": [],
      "source": [
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "def cstr(str): # cyan string\n",
        "    return bcolors.OKCYAN + str + bcolors.ENDC\n",
        "\n",
        "checkpoint_path = \"checkpoints/\" if IN_COLAB else os.path.join(\"..\", \"checkpoints/\")\n",
        "!mkdir $checkpoint_path\n",
        "\n",
        "last_checkpoint = -1\n",
        "if (last_checkpoint > -1):\n",
        "  file_path = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(last_checkpoint))\n",
        "  model.load_weights(file_path)\n",
        "  print(cstr(\"Loaded weights from {}\".format(file_path)))\n",
        "\n",
        "EPOCHS = 10 # sure...\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  print(\"Begin epoch\", epoch)\n",
        "  start = time.time()\n",
        "  train_loss.reset_states()\n",
        "  #train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  #test_accuracy.reset_states()\n",
        "  \n",
        "  for i in range(TRAIN_IMAGES // 32):\n",
        "    for j in range(32):\n",
        "      train_image = download_image(os.path.join(gcs_path, \"training\", \"color\", train_list[j + i * 32]))\n",
        "      x_train[j,:,:,:] = train_image\n",
        "     \n",
        "    # TODO(Data Team): Load in the annotations.\n",
        "    x_train = x_train.astype('float32')\n",
        "    y_train = y_train.astype('float32')\n",
        "\n",
        "    loss = train_step(x_train, y_train)\n",
        "    train_loss(loss.numpy())\n",
        "\n",
        "  for i in range(TEST_IMAGES // 32):\n",
        "    for j in range(32):\n",
        "      eval_image = download_image(os.path.join(gcs_path, \"evaluation\", \"color\", eval_list[j + i * 32]))\n",
        "      x_test[j,:,:,:] = eval_image\n",
        "    x_test = x_test.astype('float32')\n",
        "    y_test = y_test.astype('float32')\n",
        "\n",
        "    loss_test = test_step(x_test, y_test)\n",
        "    test_loss(loss.numpy())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch}, '\n",
        "    f'Time {end-start} s'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "  )\n",
        "\n",
        "  # Save the model parameters\n",
        "  if (epoch % 5 == 0):\n",
        "\n",
        "    checkpoint_filepath = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(epoch))\n",
        "    model.save_weights(checkpoint_filepath)\n",
        "    print(cstr(\"Saved weights to {}\".format(checkpoint_filepath)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FGNffUKbxtVJ"
      ],
      "machine_shape": "hm",
      "name": "HandTracking.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}