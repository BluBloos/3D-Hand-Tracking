{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BluBloos/QMIND2021-2022/blob/main/src/HandTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytgQcZUUwswL"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_ZBgm__TNlq"
      },
      "outputs": [],
      "source": [
        "# RUN THIS BLOCK ONLY WHEN IN COLAB\n",
        "\n",
        "!echo \"Initializing github repository\"\n",
        "!ls -la\n",
        "!rm -r .config/\n",
        "!rm -r sample_data/\n",
        "!git clone https://github.com/BluBloos/QMIND2021-2022/ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee72KKdTPIsZ"
      },
      "outputs": [],
      "source": [
        "# ALWAYS RUN THIS BLOCK, COLAB OR NOT\n",
        "\n",
        "# Download updated project from Github.\n",
        "!git pull\n",
        "\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "print(\"In Colab:\", IN_COLAB)\n",
        "import sys\n",
        "if (IN_COLAB):\n",
        "  sys.path.insert(1, '/content/src/')\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "#NOTE: Good resource. -> https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "import cv2 # opencv, for image resizing.\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "\n",
        "############## HELPER FUNCTIONS ############## \n",
        "# NOTE(Noah): Stole this function from Stackoverflow :)\n",
        "def rgb2gray(rgb):\n",
        "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=2)\n",
        "def resize(img, size):\n",
        "    return cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "############## HELPER FUNCTIONS ############## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSW4BpvZPIsb"
      },
      "source": [
        "# MODEL LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLws7Z0QPIsb"
      },
      "outputs": [],
      "source": [
        "# TODO(Noah): Get the MANO folders hosted in GCS so that this works again.\n",
        "#   we note that this cost was tested and is in full working order, so \n",
        "#   the only thing not working is the lack of existence of MANO_DIR. \n",
        "\n",
        "# Setup some params.\n",
        "IMAGE_SIZE = 224\n",
        "GRAYSCALE = False\n",
        "IMAGE_CHANNELS = 1 if GRAYSCALE else 3\n",
        "BATCH_SIZE = 32\n",
        "MANO_DIR = \"mano_v1_2\" if IN_COLAB else \"../mano_v1_2\"\n",
        "\n",
        "from mobilehand import MAKE_MOBILE_HAND\n",
        "from mobilehand_lfuncs import LOSS_3D\n",
        "\n",
        "MOBILE_HAND = MAKE_MOBILE_HAND(IMAGE_SIZE, IMAGE_CHANNELS, BATCH_SIZE, MANO_DIR)\n",
        "\n",
        "# INTEGRATION TEST\n",
        "input_test = tf.random.uniform(shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
        "input_test = tf.cast(input_test, tf.float32)\n",
        "output_test = MOBILE_HAND(input_test)\n",
        "print(output_test)\n",
        "\n",
        "# The lower training loop assumes that the model is set as such.\n",
        "model = MOBILE_HAND\n",
        "\n",
        "# The lower training loop also assumes that we have the loss function set like so.\n",
        "loss_fn = lambda pred, gt : LOSS_3D(pred,gt) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pebm8lODx0fu"
      },
      "source": [
        "# DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdXEqOo0qO1R"
      },
      "outputs": [],
      "source": [
        "# more params to setup.\n",
        "TRAIN_AMOUNT = 192 # must be multiple of 32\n",
        "TEST_AMOUNT = 96 # must be multiple of 32\n",
        "\n",
        "# Check if the dataset has been parsed yet. If not, parse.\n",
        "data_dir = 'RHD_small' if IN_COLAB else '../RHD_small'\n",
        "parsed_data_dir = 'SH_RHD' if IN_COLAB else '../SH_RHD'\n",
        "import parsing_data\n",
        "if not os.path.isdir(parsed_data_dir):\n",
        "  os.mkdir(parsed_data_dir)\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'evaluation'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'evaluation', 'color'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'training'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'training', 'color'))\n",
        "  parsing_data.parse_dataset(203, data_dir, parsed_data_dir)\n",
        "\n",
        "data_dir = parsed_data_dir\n",
        "\n",
        "# Load in the testing and training images.\n",
        "x_train = np.zeros( (TRAIN_AMOUNT, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) )\n",
        "y_train = np.zeros( (TRAIN_AMOUNT, 21, 3) )\n",
        "x_test = np.zeros( (TEST_AMOUNT, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) ) \n",
        "y_test = np.zeros( (TEST_AMOUNT, 21, 3) )\n",
        "\n",
        "def LoadData(dataAmount, dataType, np1):\n",
        "  path = os.path.join(data_dir, dataType, 'color')\n",
        "  \n",
        "  count = 0\n",
        "  for filename in os.listdir(path):\n",
        "    filePath = os.path.join(path, filename)\n",
        "    image = imageio.imread(filePath)\n",
        "    _image = image.astype('float32')\n",
        "    if GRAYSCALE:\n",
        "      _image = rgb2gray(_image / 255)\n",
        "    else:\n",
        "      _image = _image / 255\n",
        "    _image = resize(_image, IMAGE_SIZE)\n",
        "    np1[count, :, :, :] = _image\n",
        "    count += 1\n",
        "    if (count >= dataAmount):\n",
        "      break\n",
        "\n",
        "print(\"Loading in the training data samples...\")\n",
        "start_time = time.time()\n",
        "LoadData(TRAIN_AMOUNT, 'training', x_train)\n",
        "x_train = x_train.astype('float32')\n",
        "#y_train = y_train.astype('float32')\n",
        "end_time = time.time()\n",
        "print('Elapsed for LoadData training', end_time - start_time, 's')\n",
        "\n",
        "print(\"Loading in the evaluation data samples...\")\n",
        "start_time = time.time()\n",
        "LoadData(TEST_AMOUNT, 'evaluation', x_test)\n",
        "x_test = x_test.astype('float32')\n",
        "#y_test = y_test.astype('float32')\n",
        "end_time = time.time()\n",
        "print('Elapsed for LoadData evaluation', end_time - start_time, 's')\n",
        "\n",
        "# Test print one of the images from the dataset.\n",
        "_test = x_train[0] \n",
        "plt.imshow(_test)\n",
        "plt.show()\n",
        "#_test = y_train[0]\n",
        "#plt.imshow(np.squeeze(_test))\n",
        "#plt.show()\n",
        "\n",
        "# Batch the data for tensorflow.\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# TODO(Noah): Is it feasible to now delete all the intermediate numpy arrays?\n",
        "# TODO(Noah): Integrate code that max wrote to check if the dataset has been parsed.\n",
        "# if the dataset has not been parsed yet, parse it, then load."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3xZXThyyVta"
      },
      "source": [
        "# TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpOZpsk5rNev"
      },
      "outputs": [],
      "source": [
        "class StupidSimpleLossMetric():\n",
        "    def __init__(self):\n",
        "        self.losses = [] # empty python array \n",
        "    def __call__(self, loss):\n",
        "        self.losses.append(loss)\n",
        "    def result(self):\n",
        "        return sum(self.losses) / len(self.losses)\n",
        "    def reset_states(self):\n",
        "        self.losses = []\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # defaults should work just fine\n",
        "train_loss = StupidSimpleLossMetric()\n",
        "test_loss = StupidSimpleLossMetric()\n",
        "\n",
        "# loss_fn = keras.losses.BinaryCrossentropy(from_logits=False) # from_logits=False just means that the values are between zero and one (a probability).\n",
        "# loss_fn = lambda x, y: tf.math.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(x, y))\n",
        "\n",
        "# train_accuracy = tf.keras.metrics.MeanAbsolutePercentageError(name='train_accuracy')\n",
        "# test_accuracy = tf.keras.metrics.MeanAbsolutePercentageError(name='test_accuracy')\n",
        "\n",
        "# @tf.function Compiles a function into a callable TensorFlow graph.\n",
        "# https://www.tensorflow.org/guide/intro_to_graphs\n",
        "'''def custom_loss_func(pred, labels):\n",
        "    #return tf.math.reduce_sum( tf.math.square(labels - tf.cast(pred,tf.float64)))\n",
        "    # now trying pixel-wise cross-entropy loss\n",
        "    return -tf.math.reduce_sum(tf.math.log(pred) * labels)\n",
        "'''\n",
        "\n",
        "# Loss function unit test\n",
        "input = tf.zeros([1, 39])  # mock pred of all zeros\n",
        "label = np.expand_dims(y_train[0], axis=0)\n",
        "loss = loss_fn(input, label)\n",
        "print('Loss for pred of all zeros', loss.numpy())\n",
        "#loss2 = loss_fn(label, label)\n",
        "#print('Loss for perfect prediction', loss2.numpy())\n",
        "input2 = tf.ones([1, 39])\n",
        "loss3 = loss_fn(input2, label)\n",
        "print('Loss for pred of all ones', loss3.numpy())\n",
        "\n",
        "@tf.function\n",
        "def train_step(input, gt):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(input)\n",
        "        #loss = loss_func(predictions, segmentation_masks)\n",
        "        #loss = np.dot(tf.reshape(segmentation_masks, [102400], tf.reshape(predictions, [102400])\n",
        "        loss = loss_fn(predictions, gt)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "    #train_accuracy(labels, predictions)\n",
        "  \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  return loss_fn(predictions, labels)\n",
        "  #test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZawQmCPIsf"
      },
      "outputs": [],
      "source": [
        "# TODO: Reimplement loading in the saved model weights\n",
        "# model.load_weights(checkpoint_path)\n",
        "\n",
        "EPOCHS = 10 # sure...\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  print(\"Epoch\", epoch)\n",
        "  start = time.time()\n",
        "  train_loss.reset_states()\n",
        "  #train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  #test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    loss = train_step(images, labels)\n",
        "    train_loss(loss.numpy())\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    loss = test_step(test_images, test_labels)\n",
        "    test_loss(loss.numpy())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Time {end-start} s'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "  )\n",
        "\n",
        "  # for each epoch, we want to show the \n",
        "  #pred = model( _image )\n",
        "  #plt.imshow(np.squeeze(pred))\n",
        "  #plt.show()\n",
        "\n",
        "# Save the model parameters\n",
        "# TODO: Make it such that model parameters are saved after x many epochs as opposed to however\n",
        "#   many epochs the model will be trained in total\n",
        "#save_dir = '/content/drive/My Drive'\n",
        "#checkpoint_path = save_dir + \"/cp-{epoch:04d}.ckpt\"\n",
        "#model.save('current_model.h5py',save_path)\n",
        "#model.save_weights(checkpoint_path.format(epoch=40))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FGNffUKbxtVJ"
      ],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "HandTracking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
