{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BluBloos/QMIND2021-2022/blob/main/src/HandTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytgQcZUUwswL"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_ZBgm__TNlq"
      },
      "outputs": [],
      "source": [
        "# RUN THIS BLOCK ONLY WHEN IN COLAB\n",
        "\n",
        "!echo \"Initializing github repository\"\n",
        "!ls -la\n",
        "!rm -r .config/\n",
        "!rm -r sample_data/\n",
        "!git clone https://github.com/BluBloos/QMIND2021-2022/ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee72KKdTPIsZ"
      },
      "outputs": [],
      "source": [
        "# ALWAYS RUN THIS BLOCK, COLAB OR NOT\n",
        "\n",
        "# Download updated project from Github.\n",
        "!git pull\n",
        "\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "print(\"In Colab:\", IN_COLAB)\n",
        "import sys\n",
        "if (IN_COLAB):\n",
        "  sys.path.insert(1, '/content/src/')\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "#NOTE: Good resource. -> https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "import cv2 # opencv, for image resizing.\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "\n",
        "############## HELPER FUNCTIONS ############## \n",
        "# NOTE(Noah): Stole this function from Stackoverflow :)\n",
        "def rgb2gray(rgb):\n",
        "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=2)\n",
        "def resize(img, size):\n",
        "    return cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "############## HELPER FUNCTIONS ############## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSW4BpvZPIsb"
      },
      "source": [
        "# MODEL LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLws7Z0QPIsb"
      },
      "outputs": [],
      "source": [
        "# TODO(Noah): Get the MANO folders hosted in GCS so that this works again.\n",
        "#   We note that this cost was tested and is in full working order, so \n",
        "#   the only thing not working is the lack of existence of MANO_DIR. \n",
        "\n",
        "# Setup some params.\n",
        "IMAGE_SIZE = 224\n",
        "GRAYSCALE = False\n",
        "IMAGE_CHANNELS = 1 if GRAYSCALE else 3\n",
        "BATCH_SIZE = 32\n",
        "MANO_DIR = \"mano_v1_2\" if IN_COLAB else \"../mano_v1_2\"\n",
        "\n",
        "from mobilehand import MAKE_MOBILE_HAND\n",
        "from mobilehand_lfuncs import LOSS_3D\n",
        "\n",
        "MOBILE_HAND = MAKE_MOBILE_HAND(IMAGE_SIZE, IMAGE_CHANNELS, BATCH_SIZE, MANO_DIR)\n",
        "\n",
        "# INTEGRATION TEST\n",
        "input_test = tf.random.uniform(shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
        "input_test = tf.cast(input_test, tf.float32)\n",
        "output_test = MOBILE_HAND(input_test)\n",
        "print(output_test)\n",
        "\n",
        "# The lower training loop assumes that the model is set as such.\n",
        "model = MOBILE_HAND\n",
        "\n",
        "# The lower training loop also assumes that we have the loss function set like so.\n",
        "loss_fn = lambda pred, gt : LOSS_3D(pred,gt) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pebm8lODx0fu"
      },
      "source": [
        "# DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdXEqOo0qO1R"
      },
      "outputs": [],
      "source": [
        "# more params to setup.\n",
        "TRAIN_AMOUNT = 192 # must be multiple of 32\n",
        "TEST_AMOUNT = 96 # must be multiple of 32\n",
        "\n",
        "# Check if the dataset has been parsed yet. If not, parse.\n",
        "data_dir = 'RHD_small' if IN_COLAB else '../RHD_small'\n",
        "anno_dir = data_dir\n",
        "parsed_data_dir = 'SH_RHD' if IN_COLAB else '../SH_RHD'\n",
        "import parsing_data\n",
        "if not os.path.isdir(parsed_data_dir):\n",
        "  os.mkdir(parsed_data_dir)\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'evaluation'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'evaluation', 'color'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'training'))\n",
        "  os.mkdir(os.path.join(parsed_data_dir, 'training', 'color'))\n",
        "  parsing_data.parse_dataset(\"training\", 203, data_dir, parsed_data_dir) # parse for the training examples\n",
        "  parsing_data.parse_dataset(\"evaluation\", 203, data_dir, parsed_data_dir) # parse for the evaluation examples\n",
        "\n",
        "data_dir = parsed_data_dir\n",
        "\n",
        "# Load in the testing and training images.\n",
        "x_train = np.zeros( (TRAIN_AMOUNT, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) )\n",
        "y_train = np.zeros( (TRAIN_AMOUNT, 21, 3) )\n",
        "x_test = np.zeros( (TEST_AMOUNT, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) ) \n",
        "y_test = np.zeros( (TEST_AMOUNT, 21, 3) )\n",
        "\n",
        "def LoadData(dataAmount, dataType, anno_dir, np1, OUTPUT = False):\n",
        "  path = os.path.join(data_dir, dataType, 'color')\n",
        "  count = 0\n",
        "  index = 0\n",
        "  for filename in os.listdir(path):\n",
        "    sample_id = filename[0:5]\n",
        "    sample_id = int(sample_id)\n",
        "    if OUTPUT:\n",
        "      with open(os.path.join(anno_dir, dataType, 'anno_%s.pickle' % dataType), 'rb') as fi:\n",
        "        anno_all = pickle.load(fi)\n",
        "      # TODO(Noah): Here we have the issue of loading in the annotations sparsely into a numpy array,\n",
        "      # but the training images are loaded in densely from the preparsed dataset. \n",
        "      # So we have an issue where things are not lined up.\n",
        "      # \n",
        "      # Generally, the entire problem here changes when we start to consider the fact that we are going to\n",
        "      # do data streaming.\n",
        "      # So when we data stream, what we want to happen is a download of a single batch, where we get the train\n",
        "      # images, the test images, along with the ground truths.\n",
        "      #\n",
        "      # Thus, the task is as follows. We need to add onto the preparsing routine the ability to output the\n",
        "      # annotations alongside the images. \n",
        "      kp_visible = (anno_all[sample_id]['uv_vis'][:, 2] == 1)\n",
        "      case1 = np.sum(kp_visible[0:21])\n",
        "      case2 = np.sum(kp_visible[21:])\n",
        "      LEFT_HAND = (case1>case2)\n",
        "      if LEFT_HAND:\n",
        "        np1[index][:,:] = anno_all[sample_id]['xyz'][0:21]\n",
        "      else:\n",
        "        np1[index][:,:] = anno_all[sample_id]['xyz'][21:]      \n",
        "    else:\n",
        "      filePath = os.path.join(path, filename)\n",
        "      image = imageio.imread(filePath)\n",
        "      _image = image.astype('float32')\n",
        "      if GRAYSCALE:\n",
        "        _image = rgb2gray(_image / 255)\n",
        "      else:\n",
        "        _image = _image / 255\n",
        "      _image = resize(_image, IMAGE_SIZE)\n",
        "      \n",
        "      np1[count, :, :, :] = _image\n",
        "    \n",
        "    index += 1\n",
        "    count += 1\n",
        "    if (count >= dataAmount):\n",
        "      break\n",
        "\n",
        "print(\"Loading in the training data samples...\")\n",
        "start_time = time.time()\n",
        "LoadData(TRAIN_AMOUNT, 'training', data_dir, x_train)\n",
        "x_train = x_train.astype('float32')\n",
        "LoadData(TRAIN_AMOUNT, 'training', anno_dir, y_test, OUTPUT=True)\n",
        "y_train = y_train.astype('float32')\n",
        "end_time = time.time()\n",
        "print('Elapsed for LoadData training', end_time - start_time, 's')\n",
        "\n",
        "print(\"Loading in the evaluation data samples...\")\n",
        "start_time = time.time()\n",
        "LoadData(TEST_AMOUNT, 'evaluation', data_dir, x_test)\n",
        "x_test = x_test.astype('float32')\n",
        "LoadData(TEST_AMOUNT, 'evaluation', anno_dir, y_test, OUTPUT = True)\n",
        "y_test = y_test.astype('float32')\n",
        "end_time = time.time()\n",
        "print('Elapsed for LoadData evaluation', end_time - start_time, 's')\n",
        "\n",
        "# Test print one of the images from the dataset.\n",
        "_test = x_train[0] \n",
        "plt.imshow(_test)\n",
        "plt.show()\n",
        "# _test = y_train[0]\n",
        "# plt.imshow(np.squeeze(_test))\n",
        "# plt.show()\n",
        "\n",
        "# Batch the data for tensorflow.\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3xZXThyyVta"
      },
      "source": [
        "# TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpOZpsk5rNev"
      },
      "outputs": [],
      "source": [
        "class StupidSimpleLossMetric():\n",
        "    def __init__(self):\n",
        "        self.losses = [] # empty python array \n",
        "    def __call__(self, loss):\n",
        "        self.losses.append(loss)\n",
        "    def result(self):\n",
        "        return sum(self.losses) / len(self.losses)\n",
        "    def reset_states(self):\n",
        "        self.losses = []\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # defaults should work just fine\n",
        "train_loss = StupidSimpleLossMetric()\n",
        "test_loss = StupidSimpleLossMetric()\n",
        "\n",
        "# Loss function unit test\n",
        "input = tf.zeros([1, 39])  # mock pred of all zeros\n",
        "label = np.expand_dims(y_train[0], axis=0)\n",
        "loss = loss_fn(input, label)\n",
        "print('Loss for pred of all zeros', loss.numpy())\n",
        "#loss2 = loss_fn(label, label)\n",
        "#print('Loss for perfect prediction', loss2.numpy())\n",
        "input2 = tf.ones([1, 39])\n",
        "loss3 = loss_fn(input2, label)\n",
        "print('Loss for pred of all ones', loss3.numpy())\n",
        "\n",
        "@tf.function\n",
        "def train_step(input, gt):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(input)\n",
        "        #loss = loss_func(predictions, segmentation_masks)\n",
        "        #loss = np.dot(tf.reshape(segmentation_masks, [102400], tf.reshape(predictions, [102400])\n",
        "        loss = loss_fn(predictions, gt)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "    #train_accuracy(labels, predictions)\n",
        "  \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  return loss_fn(predictions, labels)\n",
        "  #test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZawQmCPIsf"
      },
      "outputs": [],
      "source": [
        "# TODO: Reimplement loading in the saved model weights\n",
        "# model.load_weights(checkpoint_path)\n",
        "\n",
        "EPOCHS = 10 # sure...\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  print(\"Epoch\", epoch)\n",
        "  start = time.time()\n",
        "  train_loss.reset_states()\n",
        "  #train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  #test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    loss = train_step(images, labels)\n",
        "    train_loss(loss.numpy())\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    loss = test_step(test_images, test_labels)\n",
        "    test_loss(loss.numpy())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Time {end-start} s'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "  )\n",
        "\n",
        "  # for each epoch, we want to show the \n",
        "  #pred = model( _image )\n",
        "  #plt.imshow(np.squeeze(pred))\n",
        "  #plt.show()\n",
        "\n",
        "# Save the model parameters\n",
        "# TODO: Make it such that model parameters are saved after x many epochs as opposed to however\n",
        "#   many epochs the model will be trained in total\n",
        "#save_dir = '/content/drive/My Drive'\n",
        "#checkpoint_path = save_dir + \"/cp-{epoch:04d}.ckpt\"\n",
        "#model.save('current_model.h5py',save_path)\n",
        "#model.save_weights(checkpoint_path.format(epoch=40))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FGNffUKbxtVJ"
      ],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "HandTracking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
