{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BluBloos/3D-Hand-Tracking/blob/main/src/HandTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytgQcZUUwswL"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ZBgm__TNlq",
        "outputId": "f0df5242-2be0-4eb6-db24-ba23b6f25c00"
      },
      "outputs": [],
      "source": [
        "# RUN THIS BLOCK ONLY WHEN IN COLAB\n",
        "\n",
        "!echo \"Initializing github repository\"\n",
        "!ls -la\n",
        "!rm -r .config/\n",
        "!rm -r sample_data/\n",
        "!git clone https://github.com/BluBloos/QMIND2021-2022/ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee72KKdTPIsZ",
        "outputId": "4ce35054-b395-483a-f0e7-3bb26700dba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mhint: Pulling without specifying how to reconcile divergent branches is\u001b[m\n",
            "\u001b[33mhint: discouraged. You can squelch this message by running one of the following\u001b[m\n",
            "\u001b[33mhint: commands sometime before your next pull:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint:   git config pull.rebase false  # merge (the default strategy)\u001b[m\n",
            "\u001b[33mhint:   git config pull.rebase true   # rebase\u001b[m\n",
            "\u001b[33mhint:   git config pull.ff only       # fast-forward only\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: You can replace \"git config\" with \"git config --global\" to set a default\u001b[m\n",
            "\u001b[33mhint: preference for all repositories. You can also pass --rebase, --no-rebase,\u001b[m\n",
            "\u001b[33mhint: or --ff-only on the command line to override the configured default per\u001b[m\n",
            "\u001b[33mhint: invocation.\u001b[m\n",
            "Already up to date.\n",
            "In Colab: False\n",
            "/bin/bash: nvidia-smi: command not found\n",
            "Your runtime has 17.2 gigabytes of available RAM\n",
            "Not using a high-RAM runtime\n",
            "TensorFlow version: 2.6.1\n"
          ]
        }
      ],
      "source": [
        "# ALWAYS RUN THIS BLOCK, COLAB OR NOT\n",
        "\n",
        "# Download updated project from Github.\n",
        "!git pull\n",
        "\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "print(\"In Colab:\", IN_COLAB)\n",
        "import sys\n",
        "if (IN_COLAB):\n",
        "  sys.path.insert(1, '/content/src/')\n",
        "##### HANDLE DIFFS WHEN RUNNING IN COLAB #####\n",
        "\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "########### TEST GPU AND RAM OF COLLAB INSTANCE ###########\n",
        "\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, MaxPool2D\n",
        "from tensorflow.keras import Model\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "#NOTE: Good resource. -> https://www.tensorflow.org/tutorials/quickstart/advanced\n",
        "import cv2 # opencv, for image resizing.\n",
        "######### EXTERNAL LIBRARIES #########\n",
        "\n",
        "############## HELPER FUNCTIONS ############## \n",
        "# NOTE(Noah): Stole this function from Stackoverflow :)\n",
        "def rgb2gray(rgb):\n",
        "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=2)\n",
        "def resize(img, size):\n",
        "    return cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "############## HELPER FUNCTIONS ############## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSW4BpvZPIsb"
      },
      "source": [
        "# MODEL LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "JLws7Z0QPIsb",
        "outputId": "2abde68a-e8ce-4bfb-a122-8e3d8c1ec753"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-31 06:43:06.670380: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 288)               183744    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 288)               83232     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 61)                17629     \n",
            "=================================================================\n",
            "Total params: 284,605\n",
            "Trainable params: 284,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "MANO Differentiable Layer Loaded\n",
            "Tensor(\"mano__model/norm/Sqrt:0\", shape=(512, 1), dtype=float32)\n",
            "Tensor(\"mano__model/norm_1/Sqrt:0\", shape=(512, 1), dtype=float32)\n",
            "Tensor(\"mano__model/norm_2/Sqrt:0\", shape=(512, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.3469172 ]\n",
            " [0.42290503]\n",
            " [0.01690206]\n",
            " [0.28297898]\n",
            " [0.10469353]\n",
            " [0.35470554]\n",
            " [0.        ]\n",
            " [0.30748707]\n",
            " [0.67334104]\n",
            " [0.1583239 ]\n",
            " [0.16687128]\n",
            " [0.33527845]\n",
            " [0.03983846]\n",
            " [0.3064241 ]\n",
            " [0.57727635]\n",
            " [0.01325968]\n",
            " [0.34685072]\n",
            " [0.4232153 ]\n",
            " [0.01730966]\n",
            " [0.28257325]\n",
            " [0.10534532]\n",
            " [0.35434034]\n",
            " [0.        ]\n",
            " [0.30716985]\n",
            " [0.6720887 ]\n",
            " [0.15689926]\n",
            " [0.16840509]\n",
            " [0.33743924]\n",
            " [0.03972915]\n",
            " [0.30672595]\n",
            " [0.5769123 ]\n",
            " [0.01291674]\n",
            " [0.3473565 ]\n",
            " [0.42410287]\n",
            " [0.01746576]\n",
            " [0.28507492]\n",
            " [0.10632486]\n",
            " [0.3574078 ]\n",
            " [0.        ]\n",
            " [0.3076774 ]\n",
            " [0.6754952 ]\n",
            " [0.15894584]\n",
            " [0.16939537]\n",
            " [0.33820516]\n",
            " [0.03950638]\n",
            " [0.30956146]\n",
            " [0.5817929 ]\n",
            " [0.0133473 ]\n",
            " [0.34811458]\n",
            " [0.42179483]\n",
            " [0.01643945]\n",
            " [0.2845354 ]\n",
            " [0.10527018]\n",
            " [0.35658073]\n",
            " [0.        ]\n",
            " [0.30870426]\n",
            " [0.6737473 ]\n",
            " [0.1576453 ]\n",
            " [0.16823733]\n",
            " [0.3376492 ]\n",
            " [0.03960795]\n",
            " [0.30734554]\n",
            " [0.57993644]\n",
            " [0.01315144]\n",
            " [0.34693858]\n",
            " [0.42360047]\n",
            " [0.01571584]\n",
            " [0.28433052]\n",
            " [0.10580852]\n",
            " [0.35726956]\n",
            " [0.        ]\n",
            " [0.30766156]\n",
            " [0.6743966 ]\n",
            " [0.15862523]\n",
            " [0.16810036]\n",
            " [0.3353786 ]\n",
            " [0.03923713]\n",
            " [0.30546895]\n",
            " [0.5816456 ]\n",
            " [0.01337586]\n",
            " [0.34658033]\n",
            " [0.42147204]\n",
            " [0.016248  ]\n",
            " [0.28277227]\n",
            " [0.10421209]\n",
            " [0.35590604]\n",
            " [0.        ]\n",
            " [0.3070484 ]\n",
            " [0.67381495]\n",
            " [0.15774539]\n",
            " [0.16751324]\n",
            " [0.33795536]\n",
            " [0.04007594]\n",
            " [0.30658343]\n",
            " [0.57752955]\n",
            " [0.01210339]\n",
            " [0.34765232]\n",
            " [0.42131773]\n",
            " [0.0148754 ]\n",
            " [0.28255466]\n",
            " [0.10434745]\n",
            " [0.35574996]\n",
            " [0.        ]\n",
            " [0.30600676]\n",
            " [0.6737791 ]\n",
            " [0.15636516]\n",
            " [0.16763636]\n",
            " [0.33551332]\n",
            " [0.03699877]\n",
            " [0.3066213 ]\n",
            " [0.57845825]\n",
            " [0.01262908]\n",
            " [0.34550473]\n",
            " [0.4217692 ]\n",
            " [0.0168839 ]\n",
            " [0.28433186]\n",
            " [0.10486704]\n",
            " [0.3575526 ]\n",
            " [0.        ]\n",
            " [0.3069509 ]\n",
            " [0.6756292 ]\n",
            " [0.15833472]\n",
            " [0.16807252]\n",
            " [0.33631065]\n",
            " [0.0389886 ]\n",
            " [0.30607423]\n",
            " [0.57965475]\n",
            " [0.01382779]\n",
            " [0.34807318]\n",
            " [0.42354417]\n",
            " [0.0161793 ]\n",
            " [0.28374702]\n",
            " [0.10496968]\n",
            " [0.35734296]\n",
            " [0.        ]\n",
            " [0.3085164 ]\n",
            " [0.67280716]\n",
            " [0.15681526]\n",
            " [0.16909866]\n",
            " [0.33551362]\n",
            " [0.0388986 ]\n",
            " [0.30566913]\n",
            " [0.5806734 ]\n",
            " [0.0132464 ]\n",
            " [0.3471734 ]\n",
            " [0.42075327]\n",
            " [0.01610789]\n",
            " [0.28342375]\n",
            " [0.10549372]\n",
            " [0.35694876]\n",
            " [0.        ]\n",
            " [0.30805537]\n",
            " [0.6724526 ]\n",
            " [0.15540935]\n",
            " [0.16913745]\n",
            " [0.33608383]\n",
            " [0.0390577 ]\n",
            " [0.3042438 ]\n",
            " [0.5784802 ]\n",
            " [0.01379743]\n",
            " [0.34777668]\n",
            " [0.4224239 ]\n",
            " [0.01684052]\n",
            " [0.28764468]\n",
            " [0.10457966]\n",
            " [0.36046097]\n",
            " [0.        ]\n",
            " [0.30879536]\n",
            " [0.67735726]\n",
            " [0.15718131]\n",
            " [0.17036597]\n",
            " [0.3397064 ]\n",
            " [0.03903197]\n",
            " [0.3099481 ]\n",
            " [0.58272517]\n",
            " [0.01196484]\n",
            " [0.34714836]\n",
            " [0.42053163]\n",
            " [0.01548601]\n",
            " [0.28589115]\n",
            " [0.10553987]\n",
            " [0.35905895]\n",
            " [0.        ]\n",
            " [0.30682853]\n",
            " [0.6763927 ]\n",
            " [0.15656886]\n",
            " [0.17062186]\n",
            " [0.3379531 ]\n",
            " [0.03789097]\n",
            " [0.30664077]\n",
            " [0.5818821 ]\n",
            " [0.01267264]\n",
            " [0.34898525]\n",
            " [0.42081195]\n",
            " [0.01514429]\n",
            " [0.28192267]\n",
            " [0.10505367]\n",
            " [0.3541444 ]\n",
            " [0.        ]\n",
            " [0.30782607]\n",
            " [0.670395  ]\n",
            " [0.15847635]\n",
            " [0.16611516]\n",
            " [0.33577824]\n",
            " [0.04010417]\n",
            " [0.3056009 ]\n",
            " [0.5766451 ]\n",
            " [0.01246252]\n",
            " [0.34727135]\n",
            " [0.41793534]\n",
            " [0.01367613]\n",
            " [0.2837743 ]\n",
            " [0.1039281 ]\n",
            " [0.35837   ]\n",
            " [0.        ]\n",
            " [0.3071743 ]\n",
            " [0.6720132 ]\n",
            " [0.15801382]\n",
            " [0.1677195 ]\n",
            " [0.33276963]\n",
            " [0.03828708]\n",
            " [0.30167195]\n",
            " [0.58022094]\n",
            " [0.01534332]\n",
            " [0.3468357 ]\n",
            " [0.42045757]\n",
            " [0.01513157]\n",
            " [0.28386226]\n",
            " [0.10427316]\n",
            " [0.3564257 ]\n",
            " [0.        ]\n",
            " [0.307377  ]\n",
            " [0.6736821 ]\n",
            " [0.15924199]\n",
            " [0.16759644]\n",
            " [0.33567113]\n",
            " [0.04043458]\n",
            " [0.30563453]\n",
            " [0.58043367]\n",
            " [0.0128639 ]\n",
            " [0.3473446 ]\n",
            " [0.42081377]\n",
            " [0.01555517]\n",
            " [0.2815071 ]\n",
            " [0.10561208]\n",
            " [0.35479322]\n",
            " [0.        ]\n",
            " [0.30682907]\n",
            " [0.67193246]\n",
            " [0.15666626]\n",
            " [0.16740283]\n",
            " [0.3364016 ]\n",
            " [0.03969815]\n",
            " [0.3066507 ]\n",
            " [0.5767274 ]\n",
            " [0.0126571 ]\n",
            " [0.34562537]\n",
            " [0.41923288]\n",
            " [0.01653336]\n",
            " [0.28449836]\n",
            " [0.1036526 ]\n",
            " [0.35662746]\n",
            " [0.        ]\n",
            " [0.30715948]\n",
            " [0.6723203 ]\n",
            " [0.1561186 ]\n",
            " [0.16915315]\n",
            " [0.33598992]\n",
            " [0.03966449]\n",
            " [0.30518964]\n",
            " [0.5770917 ]\n",
            " [0.01380729]\n",
            " [0.34657347]\n",
            " [0.42245272]\n",
            " [0.0160669 ]\n",
            " [0.28514528]\n",
            " [0.10414882]\n",
            " [0.3581669 ]\n",
            " [0.        ]\n",
            " [0.30762902]\n",
            " [0.6731551 ]\n",
            " [0.15794551]\n",
            " [0.16797972]\n",
            " [0.3349568 ]\n",
            " [0.03850225]\n",
            " [0.30473754]\n",
            " [0.58062035]\n",
            " [0.01421189]\n",
            " [0.34545094]\n",
            " [0.42288533]\n",
            " [0.01638847]\n",
            " [0.28493676]\n",
            " [0.10490776]\n",
            " [0.35795027]\n",
            " [0.        ]\n",
            " [0.30806747]\n",
            " [0.6748482 ]\n",
            " [0.15799867]\n",
            " [0.17101187]\n",
            " [0.33697692]\n",
            " [0.03993982]\n",
            " [0.3076572 ]\n",
            " [0.58193797]\n",
            " [0.01265455]\n",
            " [0.34506148]\n",
            " [0.42278752]\n",
            " [0.01720821]\n",
            " [0.2845883 ]\n",
            " [0.10511529]\n",
            " [0.3563095 ]\n",
            " [0.        ]\n",
            " [0.30847266]\n",
            " [0.67424905]\n",
            " [0.15825346]\n",
            " [0.16948818]\n",
            " [0.33610296]\n",
            " [0.04114799]\n",
            " [0.3072754 ]\n",
            " [0.5792872 ]\n",
            " [0.0135033 ]\n",
            " [0.34643355]\n",
            " [0.4183429 ]\n",
            " [0.0125674 ]\n",
            " [0.2833323 ]\n",
            " [0.10333728]\n",
            " [0.3586855 ]\n",
            " [0.        ]\n",
            " [0.30795082]\n",
            " [0.6726382 ]\n",
            " [0.15971866]\n",
            " [0.16663885]\n",
            " [0.33272898]\n",
            " [0.03829891]\n",
            " [0.29840863]\n",
            " [0.58221775]\n",
            " [0.01479951]\n",
            " [0.3467539 ]\n",
            " [0.4209554 ]\n",
            " [0.01681187]\n",
            " [0.28262523]\n",
            " [0.10540324]\n",
            " [0.35551623]\n",
            " [0.        ]\n",
            " [0.3075006 ]\n",
            " [0.6711996 ]\n",
            " [0.15662692]\n",
            " [0.1687818 ]\n",
            " [0.3361493 ]\n",
            " [0.0408302 ]\n",
            " [0.30544302]\n",
            " [0.5770913 ]\n",
            " [0.01344755]\n",
            " [0.3477167 ]\n",
            " [0.42146122]\n",
            " [0.01605272]\n",
            " [0.28413838]\n",
            " [0.10504219]\n",
            " [0.35546213]\n",
            " [0.        ]\n",
            " [0.30675033]\n",
            " [0.67333114]\n",
            " [0.15795729]\n",
            " [0.16774547]\n",
            " [0.33678   ]\n",
            " [0.04024493]\n",
            " [0.30832312]\n",
            " [0.57831234]\n",
            " [0.01231501]\n",
            " [0.34801343]\n",
            " [0.4216833 ]\n",
            " [0.01518099]\n",
            " [0.2832591 ]\n",
            " [0.10382987]\n",
            " [0.3563902 ]\n",
            " [0.        ]\n",
            " [0.3064382 ]\n",
            " [0.67148167]\n",
            " [0.1559119 ]\n",
            " [0.16818719]\n",
            " [0.33473635]\n",
            " [0.03860551]\n",
            " [0.3040511 ]\n",
            " [0.5779945 ]\n",
            " [0.01260772]\n",
            " [0.3462065 ]\n",
            " [0.42119876]\n",
            " [0.01751669]\n",
            " [0.2832732 ]\n",
            " [0.10507537]\n",
            " [0.35572344]\n",
            " [0.        ]\n",
            " [0.307553  ]\n",
            " [0.6723655 ]\n",
            " [0.15542828]\n",
            " [0.16913435]\n",
            " [0.336505  ]\n",
            " [0.04044416]\n",
            " [0.30672532]\n",
            " [0.5758994 ]\n",
            " [0.01304964]\n",
            " [0.34830144]\n",
            " [0.4226311 ]\n",
            " [0.01623355]\n",
            " [0.2824293 ]\n",
            " [0.10576572]\n",
            " [0.35444346]\n",
            " [0.        ]\n",
            " [0.30651385]\n",
            " [0.67330736]\n",
            " [0.1605655 ]\n",
            " [0.16569717]\n",
            " [0.33639294]\n",
            " [0.0389892 ]\n",
            " [0.30690825]\n",
            " [0.5783118 ]\n",
            " [0.0127499 ]\n",
            " [0.34518614]\n",
            " [0.4240256 ]\n",
            " [0.01627684]\n",
            " [0.2848796 ]\n",
            " [0.1054401 ]\n",
            " [0.3588255 ]\n",
            " [0.        ]\n",
            " [0.30821955]\n",
            " [0.67735815]\n",
            " [0.1595312 ]\n",
            " [0.17045343]\n",
            " [0.33547536]\n",
            " [0.03970212]\n",
            " [0.30522716]\n",
            " [0.5833763 ]\n",
            " [0.013377  ]\n",
            " [0.34880474]\n",
            " [0.42078888]\n",
            " [0.01485431]\n",
            " [0.28022465]\n",
            " [0.10546521]\n",
            " [0.3547498 ]\n",
            " [0.        ]\n",
            " [0.3065    ]\n",
            " [0.6713258 ]\n",
            " [0.15626794]\n",
            " [0.16840695]\n",
            " [0.3359026 ]\n",
            " [0.03959029]\n",
            " [0.3062355 ]\n",
            " [0.57763225]\n",
            " [0.01287486]\n",
            " [0.34720325]\n",
            " [0.42410806]\n",
            " [0.01799803]\n",
            " [0.28407985]\n",
            " [0.10653324]\n",
            " [0.35465822]\n",
            " [0.        ]\n",
            " [0.3070789 ]\n",
            " [0.6729134 ]\n",
            " [0.15766905]\n",
            " [0.16728692]\n",
            " [0.33704448]\n",
            " [0.03980539]\n",
            " [0.30932897]\n",
            " [0.57608014]\n",
            " [0.01272185]\n",
            " [0.3462089 ]\n",
            " [0.42328817]\n",
            " [0.01758382]\n",
            " [0.28462487]\n",
            " [0.10588583]\n",
            " [0.35567224]\n",
            " [0.        ]\n",
            " [0.3074272 ]\n",
            " [0.67562324]\n",
            " [0.15685226]\n",
            " [0.16949543]\n",
            " [0.33702427]\n",
            " [0.03954251]\n",
            " [0.30825338]\n",
            " [0.57905036]\n",
            " [0.01294896]\n",
            " [0.34871057]\n",
            " [0.42321652]\n",
            " [0.01885018]\n",
            " [0.28405413]\n",
            " [0.10687922]\n",
            " [0.355027  ]\n",
            " [0.        ]\n",
            " [0.30765894]\n",
            " [0.67553985]\n",
            " [0.15901971]\n",
            " [0.16710821]\n",
            " [0.33753207]\n",
            " [0.03944439]\n",
            " [0.30993962]\n",
            " [0.57778275]\n",
            " [0.01166064]\n",
            " [0.3460432 ]\n",
            " [0.42206147]\n",
            " [0.01557312]\n",
            " [0.28085557]\n",
            " [0.10477167]\n",
            " [0.35435915]\n",
            " [0.        ]\n",
            " [0.3059102 ]\n",
            " [0.6729038 ]\n",
            " [0.15777095]\n",
            " [0.16808072]\n",
            " [0.33521527]\n",
            " [0.03907635]\n",
            " [0.3061344 ]\n",
            " [0.5769221 ]\n",
            " [0.01334964]], shape=(512, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.3469172 ]\n",
            " [0.42290503]\n",
            " [0.01690206]\n",
            " [0.28297898]\n",
            " [0.10469353]\n",
            " [0.35470554]\n",
            " [0.        ]\n",
            " [0.30748707]\n",
            " [0.67334104]\n",
            " [0.1583239 ]\n",
            " [0.16687128]\n",
            " [0.33527845]\n",
            " [0.03983846]\n",
            " [0.3064241 ]\n",
            " [0.57727635]\n",
            " [0.01325968]\n",
            " [0.34685072]\n",
            " [0.4232153 ]\n",
            " [0.01730966]\n",
            " [0.28257325]\n",
            " [0.10534532]\n",
            " [0.35434034]\n",
            " [0.        ]\n",
            " [0.30716985]\n",
            " [0.6720887 ]\n",
            " [0.15689926]\n",
            " [0.16840509]\n",
            " [0.33743924]\n",
            " [0.03972915]\n",
            " [0.30672595]\n",
            " [0.5769123 ]\n",
            " [0.01291674]\n",
            " [0.3473565 ]\n",
            " [0.42410287]\n",
            " [0.01746576]\n",
            " [0.28507492]\n",
            " [0.10632486]\n",
            " [0.3574078 ]\n",
            " [0.        ]\n",
            " [0.3076774 ]\n",
            " [0.6754952 ]\n",
            " [0.15894584]\n",
            " [0.16939537]\n",
            " [0.33820516]\n",
            " [0.03950638]\n",
            " [0.30956146]\n",
            " [0.5817929 ]\n",
            " [0.0133473 ]\n",
            " [0.34811458]\n",
            " [0.42179483]\n",
            " [0.01643945]\n",
            " [0.2845354 ]\n",
            " [0.10527018]\n",
            " [0.35658073]\n",
            " [0.        ]\n",
            " [0.30870426]\n",
            " [0.6737473 ]\n",
            " [0.1576453 ]\n",
            " [0.16823733]\n",
            " [0.3376492 ]\n",
            " [0.03960795]\n",
            " [0.30734554]\n",
            " [0.57993644]\n",
            " [0.01315144]\n",
            " [0.34693858]\n",
            " [0.42360047]\n",
            " [0.01571584]\n",
            " [0.28433052]\n",
            " [0.10580852]\n",
            " [0.35726956]\n",
            " [0.        ]\n",
            " [0.30766156]\n",
            " [0.6743966 ]\n",
            " [0.15862523]\n",
            " [0.16810036]\n",
            " [0.3353786 ]\n",
            " [0.03923713]\n",
            " [0.30546895]\n",
            " [0.5816456 ]\n",
            " [0.01337586]\n",
            " [0.34658033]\n",
            " [0.42147204]\n",
            " [0.016248  ]\n",
            " [0.28277227]\n",
            " [0.10421209]\n",
            " [0.35590604]\n",
            " [0.        ]\n",
            " [0.3070484 ]\n",
            " [0.67381495]\n",
            " [0.15774539]\n",
            " [0.16751324]\n",
            " [0.33795536]\n",
            " [0.04007594]\n",
            " [0.30658343]\n",
            " [0.57752955]\n",
            " [0.01210339]\n",
            " [0.34765232]\n",
            " [0.42131773]\n",
            " [0.0148754 ]\n",
            " [0.28255466]\n",
            " [0.10434745]\n",
            " [0.35574996]\n",
            " [0.        ]\n",
            " [0.30600676]\n",
            " [0.6737791 ]\n",
            " [0.15636516]\n",
            " [0.16763636]\n",
            " [0.33551332]\n",
            " [0.03699877]\n",
            " [0.3066213 ]\n",
            " [0.57845825]\n",
            " [0.01262908]\n",
            " [0.34550473]\n",
            " [0.4217692 ]\n",
            " [0.0168839 ]\n",
            " [0.28433186]\n",
            " [0.10486704]\n",
            " [0.3575526 ]\n",
            " [0.        ]\n",
            " [0.3069509 ]\n",
            " [0.6756292 ]\n",
            " [0.15833472]\n",
            " [0.16807252]\n",
            " [0.33631065]\n",
            " [0.0389886 ]\n",
            " [0.30607423]\n",
            " [0.57965475]\n",
            " [0.01382779]\n",
            " [0.34807318]\n",
            " [0.42354417]\n",
            " [0.0161793 ]\n",
            " [0.28374702]\n",
            " [0.10496968]\n",
            " [0.35734296]\n",
            " [0.        ]\n",
            " [0.3085164 ]\n",
            " [0.67280716]\n",
            " [0.15681526]\n",
            " [0.16909866]\n",
            " [0.33551362]\n",
            " [0.0388986 ]\n",
            " [0.30566913]\n",
            " [0.5806734 ]\n",
            " [0.0132464 ]\n",
            " [0.3471734 ]\n",
            " [0.42075327]\n",
            " [0.01610789]\n",
            " [0.28342375]\n",
            " [0.10549372]\n",
            " [0.35694876]\n",
            " [0.        ]\n",
            " [0.30805537]\n",
            " [0.6724526 ]\n",
            " [0.15540935]\n",
            " [0.16913745]\n",
            " [0.33608383]\n",
            " [0.0390577 ]\n",
            " [0.3042438 ]\n",
            " [0.5784802 ]\n",
            " [0.01379743]\n",
            " [0.34777668]\n",
            " [0.4224239 ]\n",
            " [0.01684052]\n",
            " [0.28764468]\n",
            " [0.10457966]\n",
            " [0.36046097]\n",
            " [0.        ]\n",
            " [0.30879536]\n",
            " [0.67735726]\n",
            " [0.15718131]\n",
            " [0.17036597]\n",
            " [0.3397064 ]\n",
            " [0.03903197]\n",
            " [0.3099481 ]\n",
            " [0.58272517]\n",
            " [0.01196484]\n",
            " [0.34714836]\n",
            " [0.42053163]\n",
            " [0.01548601]\n",
            " [0.28589115]\n",
            " [0.10553987]\n",
            " [0.35905895]\n",
            " [0.        ]\n",
            " [0.30682853]\n",
            " [0.6763927 ]\n",
            " [0.15656886]\n",
            " [0.17062186]\n",
            " [0.3379531 ]\n",
            " [0.03789097]\n",
            " [0.30664077]\n",
            " [0.5818821 ]\n",
            " [0.01267264]\n",
            " [0.34898525]\n",
            " [0.42081195]\n",
            " [0.01514429]\n",
            " [0.28192267]\n",
            " [0.10505367]\n",
            " [0.3541444 ]\n",
            " [0.        ]\n",
            " [0.30782607]\n",
            " [0.670395  ]\n",
            " [0.15847635]\n",
            " [0.16611516]\n",
            " [0.33577824]\n",
            " [0.04010417]\n",
            " [0.3056009 ]\n",
            " [0.5766451 ]\n",
            " [0.01246252]\n",
            " [0.34727135]\n",
            " [0.41793534]\n",
            " [0.01367613]\n",
            " [0.2837743 ]\n",
            " [0.1039281 ]\n",
            " [0.35837   ]\n",
            " [0.        ]\n",
            " [0.3071743 ]\n",
            " [0.6720132 ]\n",
            " [0.15801382]\n",
            " [0.1677195 ]\n",
            " [0.33276963]\n",
            " [0.03828708]\n",
            " [0.30167195]\n",
            " [0.58022094]\n",
            " [0.01534332]\n",
            " [0.3468357 ]\n",
            " [0.42045757]\n",
            " [0.01513157]\n",
            " [0.28386226]\n",
            " [0.10427316]\n",
            " [0.3564257 ]\n",
            " [0.        ]\n",
            " [0.307377  ]\n",
            " [0.6736821 ]\n",
            " [0.15924199]\n",
            " [0.16759644]\n",
            " [0.33567113]\n",
            " [0.04043458]\n",
            " [0.30563453]\n",
            " [0.58043367]\n",
            " [0.0128639 ]\n",
            " [0.3473446 ]\n",
            " [0.42081377]\n",
            " [0.01555517]\n",
            " [0.2815071 ]\n",
            " [0.10561208]\n",
            " [0.35479322]\n",
            " [0.        ]\n",
            " [0.30682907]\n",
            " [0.67193246]\n",
            " [0.15666626]\n",
            " [0.16740283]\n",
            " [0.3364016 ]\n",
            " [0.03969815]\n",
            " [0.3066507 ]\n",
            " [0.5767274 ]\n",
            " [0.0126571 ]\n",
            " [0.34562537]\n",
            " [0.41923288]\n",
            " [0.01653336]\n",
            " [0.28449836]\n",
            " [0.1036526 ]\n",
            " [0.35662746]\n",
            " [0.        ]\n",
            " [0.30715948]\n",
            " [0.6723203 ]\n",
            " [0.1561186 ]\n",
            " [0.16915315]\n",
            " [0.33598992]\n",
            " [0.03966449]\n",
            " [0.30518964]\n",
            " [0.5770917 ]\n",
            " [0.01380729]\n",
            " [0.34657347]\n",
            " [0.42245272]\n",
            " [0.0160669 ]\n",
            " [0.28514528]\n",
            " [0.10414882]\n",
            " [0.3581669 ]\n",
            " [0.        ]\n",
            " [0.30762902]\n",
            " [0.6731551 ]\n",
            " [0.15794551]\n",
            " [0.16797972]\n",
            " [0.3349568 ]\n",
            " [0.03850225]\n",
            " [0.30473754]\n",
            " [0.58062035]\n",
            " [0.01421189]\n",
            " [0.34545094]\n",
            " [0.42288533]\n",
            " [0.01638847]\n",
            " [0.28493676]\n",
            " [0.10490776]\n",
            " [0.35795027]\n",
            " [0.        ]\n",
            " [0.30806747]\n",
            " [0.6748482 ]\n",
            " [0.15799867]\n",
            " [0.17101187]\n",
            " [0.33697692]\n",
            " [0.03993982]\n",
            " [0.3076572 ]\n",
            " [0.58193797]\n",
            " [0.01265455]\n",
            " [0.34506148]\n",
            " [0.42278752]\n",
            " [0.01720821]\n",
            " [0.2845883 ]\n",
            " [0.10511529]\n",
            " [0.3563095 ]\n",
            " [0.        ]\n",
            " [0.30847266]\n",
            " [0.67424905]\n",
            " [0.15825346]\n",
            " [0.16948818]\n",
            " [0.33610296]\n",
            " [0.04114799]\n",
            " [0.3072754 ]\n",
            " [0.5792872 ]\n",
            " [0.0135033 ]\n",
            " [0.34643355]\n",
            " [0.4183429 ]\n",
            " [0.0125674 ]\n",
            " [0.2833323 ]\n",
            " [0.10333728]\n",
            " [0.3586855 ]\n",
            " [0.        ]\n",
            " [0.30795082]\n",
            " [0.6726382 ]\n",
            " [0.15971866]\n",
            " [0.16663885]\n",
            " [0.33272898]\n",
            " [0.03829891]\n",
            " [0.29840863]\n",
            " [0.58221775]\n",
            " [0.01479951]\n",
            " [0.3467539 ]\n",
            " [0.4209554 ]\n",
            " [0.01681187]\n",
            " [0.28262523]\n",
            " [0.10540324]\n",
            " [0.35551623]\n",
            " [0.        ]\n",
            " [0.3075006 ]\n",
            " [0.6711996 ]\n",
            " [0.15662692]\n",
            " [0.1687818 ]\n",
            " [0.3361493 ]\n",
            " [0.0408302 ]\n",
            " [0.30544302]\n",
            " [0.5770913 ]\n",
            " [0.01344755]\n",
            " [0.3477167 ]\n",
            " [0.42146122]\n",
            " [0.01605272]\n",
            " [0.28413838]\n",
            " [0.10504219]\n",
            " [0.35546213]\n",
            " [0.        ]\n",
            " [0.30675033]\n",
            " [0.67333114]\n",
            " [0.15795729]\n",
            " [0.16774547]\n",
            " [0.33678   ]\n",
            " [0.04024493]\n",
            " [0.30832312]\n",
            " [0.57831234]\n",
            " [0.01231501]\n",
            " [0.34801343]\n",
            " [0.4216833 ]\n",
            " [0.01518099]\n",
            " [0.2832591 ]\n",
            " [0.10382987]\n",
            " [0.3563902 ]\n",
            " [0.        ]\n",
            " [0.3064382 ]\n",
            " [0.67148167]\n",
            " [0.1559119 ]\n",
            " [0.16818719]\n",
            " [0.33473635]\n",
            " [0.03860551]\n",
            " [0.3040511 ]\n",
            " [0.5779945 ]\n",
            " [0.01260772]\n",
            " [0.3462065 ]\n",
            " [0.42119876]\n",
            " [0.01751669]\n",
            " [0.2832732 ]\n",
            " [0.10507537]\n",
            " [0.35572344]\n",
            " [0.        ]\n",
            " [0.307553  ]\n",
            " [0.6723655 ]\n",
            " [0.15542828]\n",
            " [0.16913435]\n",
            " [0.336505  ]\n",
            " [0.04044416]\n",
            " [0.30672532]\n",
            " [0.5758994 ]\n",
            " [0.01304964]\n",
            " [0.34830144]\n",
            " [0.4226311 ]\n",
            " [0.01623355]\n",
            " [0.2824293 ]\n",
            " [0.10576572]\n",
            " [0.35444346]\n",
            " [0.        ]\n",
            " [0.30651385]\n",
            " [0.67330736]\n",
            " [0.1605655 ]\n",
            " [0.16569717]\n",
            " [0.33639294]\n",
            " [0.0389892 ]\n",
            " [0.30690825]\n",
            " [0.5783118 ]\n",
            " [0.0127499 ]\n",
            " [0.34518614]\n",
            " [0.4240256 ]\n",
            " [0.01627684]\n",
            " [0.2848796 ]\n",
            " [0.1054401 ]\n",
            " [0.3588255 ]\n",
            " [0.        ]\n",
            " [0.30821955]\n",
            " [0.67735815]\n",
            " [0.1595312 ]\n",
            " [0.17045343]\n",
            " [0.33547536]\n",
            " [0.03970212]\n",
            " [0.30522716]\n",
            " [0.5833763 ]\n",
            " [0.013377  ]\n",
            " [0.34880474]\n",
            " [0.42078888]\n",
            " [0.01485431]\n",
            " [0.28022465]\n",
            " [0.10546521]\n",
            " [0.3547498 ]\n",
            " [0.        ]\n",
            " [0.3065    ]\n",
            " [0.6713258 ]\n",
            " [0.15626794]\n",
            " [0.16840695]\n",
            " [0.3359026 ]\n",
            " [0.03959029]\n",
            " [0.3062355 ]\n",
            " [0.57763225]\n",
            " [0.01287486]\n",
            " [0.34720325]\n",
            " [0.42410806]\n",
            " [0.01799803]\n",
            " [0.28407985]\n",
            " [0.10653324]\n",
            " [0.35465822]\n",
            " [0.        ]\n",
            " [0.3070789 ]\n",
            " [0.6729134 ]\n",
            " [0.15766905]\n",
            " [0.16728692]\n",
            " [0.33704448]\n",
            " [0.03980539]\n",
            " [0.30932897]\n",
            " [0.57608014]\n",
            " [0.01272185]\n",
            " [0.3462089 ]\n",
            " [0.42328817]\n",
            " [0.01758382]\n",
            " [0.28462487]\n",
            " [0.10588583]\n",
            " [0.35567224]\n",
            " [0.        ]\n",
            " [0.3074272 ]\n",
            " [0.67562324]\n",
            " [0.15685226]\n",
            " [0.16949543]\n",
            " [0.33702427]\n",
            " [0.03954251]\n",
            " [0.30825338]\n",
            " [0.57905036]\n",
            " [0.01294896]\n",
            " [0.34871057]\n",
            " [0.42321652]\n",
            " [0.01885018]\n",
            " [0.28405413]\n",
            " [0.10687922]\n",
            " [0.355027  ]\n",
            " [0.        ]\n",
            " [0.30765894]\n",
            " [0.67553985]\n",
            " [0.15901971]\n",
            " [0.16710821]\n",
            " [0.33753207]\n",
            " [0.03944439]\n",
            " [0.30993962]\n",
            " [0.57778275]\n",
            " [0.01166064]\n",
            " [0.3460432 ]\n",
            " [0.42206147]\n",
            " [0.01557312]\n",
            " [0.28085557]\n",
            " [0.10477167]\n",
            " [0.35435915]\n",
            " [0.        ]\n",
            " [0.3059102 ]\n",
            " [0.6729038 ]\n",
            " [0.15777095]\n",
            " [0.16808072]\n",
            " [0.33521527]\n",
            " [0.03907635]\n",
            " [0.3061344 ]\n",
            " [0.5769221 ]\n",
            " [0.01334964]], shape=(512, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]], shape=(512, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 4.1180003e-01  6.3284701e-03  4.3909535e-01]\n",
            "  [ 3.3637252e-01 -7.0301816e-05  4.8794886e-01]\n",
            "  [ 3.0871674e-01 -8.1673432e-03  5.0358164e-01]\n",
            "  ...\n",
            "  [ 2.4472751e-01 -9.6699921e-03  4.7785693e-01]\n",
            "  [ 2.5228754e-01 -1.4724652e-02  4.5685440e-01]\n",
            "  [ 2.8968716e-01 -3.6952980e-02  4.1625577e-01]]\n",
            "\n",
            " [[ 4.1302690e-01  6.3281255e-03  4.3901649e-01]\n",
            "  [ 3.3760777e-01 -1.1964701e-05  4.8788413e-01]\n",
            "  [ 3.0996433e-01 -8.0793910e-03  5.0355232e-01]\n",
            "  ...\n",
            "  [ 2.4595825e-01 -9.6282307e-03  4.7781241e-01]\n",
            "  [ 2.5357157e-01 -1.4877154e-02  4.5681196e-01]\n",
            "  [ 2.9087448e-01 -3.6978357e-02  4.1624773e-01]]\n",
            "\n",
            " [[ 4.1314635e-01  6.3285725e-03  4.3984541e-01]\n",
            "  [ 3.3776107e-01  5.4006465e-05  4.8877618e-01]\n",
            "  [ 3.1015512e-01 -8.0147767e-03  5.0451165e-01]\n",
            "  ...\n",
            "  [ 2.4614416e-01 -9.7357277e-03  4.7873360e-01]\n",
            "  [ 2.5372976e-01 -1.5034821e-02  4.5769021e-01]\n",
            "  [ 2.9114160e-01 -3.7182704e-02  4.1716638e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 4.1151643e-01  6.3281264e-03  4.3985620e-01]\n",
            "  [ 3.3605945e-01 -3.3592340e-05  4.8866826e-01]\n",
            "  [ 3.0843532e-01 -8.1187859e-03  5.0436455e-01]\n",
            "  ...\n",
            "  [ 2.4443267e-01 -9.6846810e-03  4.7850406e-01]\n",
            "  [ 2.5204524e-01 -1.4924330e-02  4.5748633e-01]\n",
            "  [ 2.8948000e-01 -3.7035406e-02  4.1697884e-01]]\n",
            "\n",
            " [[ 4.1499513e-01  6.3293958e-03  4.4014487e-01]\n",
            "  [ 3.3965865e-01 -2.7596019e-05  4.8915443e-01]\n",
            "  [ 3.1205970e-01 -8.0654547e-03  5.0492269e-01]\n",
            "  ...\n",
            "  [ 2.4798343e-01 -9.6427631e-03  4.7921422e-01]\n",
            "  [ 2.5557330e-01 -1.4938717e-02  4.5822927e-01]\n",
            "  [ 2.9292345e-01 -3.7075981e-02  4.1755545e-01]]\n",
            "\n",
            " [[ 4.1272581e-01  6.3281301e-03  4.3819982e-01]\n",
            "  [ 3.3726102e-01 -4.6925619e-05  4.8699325e-01]\n",
            "  [ 3.0959094e-01 -8.0972221e-03  5.0262392e-01]\n",
            "  ...\n",
            "  [ 2.4562348e-01 -9.6458253e-03  4.7683471e-01]\n",
            "  [ 2.5320184e-01 -1.4760472e-02  4.5578232e-01]\n",
            "  [ 2.9057130e-01 -3.6903568e-02  4.1530836e-01]]], shape=(32, 21, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# TODO(Noah): Get the MANO folders hosted in GCS so that this works again.\n",
        "#   We note that this cost was tested and is in full working order, so \n",
        "#   the only thing not working is the lack of existence of MANO_DIR. \n",
        "\n",
        "# Setup some params.\n",
        "IMAGE_SIZE = 224\n",
        "GRAYSCALE = False\n",
        "IMAGE_CHANNELS = 1 if GRAYSCALE else 3\n",
        "BATCH_SIZE = 32\n",
        "MANO_DIR = \"mano_v1_2\" if IN_COLAB else \"../mano_v1_2\"\n",
        "\n",
        "from mobilehand import MAKE_MOBILE_HAND\n",
        "from mobilehand_lfuncs import LOSS_3D\n",
        "\n",
        "MOBILE_HAND = MAKE_MOBILE_HAND(IMAGE_SIZE, IMAGE_CHANNELS, BATCH_SIZE, MANO_DIR)\n",
        "\n",
        "# INTEGRATION TEST\n",
        "input_test = tf.random.uniform(shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
        "input_test = tf.cast(input_test, tf.float32)\n",
        "output_test = MOBILE_HAND(input_test)\n",
        "print(output_test)\n",
        "\n",
        "# The lower training loop assumes that the model is set as such.\n",
        "model = MOBILE_HAND\n",
        "\n",
        "# The lower training loop also assumes that we have the loss function set like so.\n",
        "loss_fn = lambda pred, gt : LOSS_3D(pred,gt) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pebm8lODx0fu"
      },
      "source": [
        "# DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7SDaXTQZuF0y",
        "outputId": "97e85fdf-f59d-4468-c30e-c1506a4852cc"
      },
      "outputs": [],
      "source": [
        "from matplotlib.image import imread\n",
        "\n",
        "# NOTE(Noah): gcs code will on work on the colab as this code is Ubuntu specific.\n",
        "# I attempted to install gcsfuse on my macOS machine, but I have a version that is too new.\n",
        "# also, gcsfuse simply does not work on Windows.\n",
        "#\n",
        "# gcsfuse is actually beta software.\n",
        "if IN_COLAB:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # we know that we are on an Ubuntu machine.\n",
        "  # Thus, installing gcsfuse will be done via the Ubuntu instructions.\n",
        "  # https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/installing.md#ubuntu-and-debian-latest-releases\n",
        "  !echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "  !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "  \n",
        "  # -y in apt-get will assume \"yes\" as the answer to all prompts.\n",
        "  # -q in apt-get will make things \"quiet\" for us. Nice!\n",
        "  !sudo apt-get -y -q update\n",
        "  !sudo apt-get -y -q install gcsfuse\n",
        "\n",
        "  !mkdir -p data\n",
        "  !gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 shd_final data\n",
        "\n",
        "def download_image(path):\n",
        "  image = imageio.imread(path)\n",
        "  _image = image.astype('float32')\n",
        "  if GRAYSCALE:\n",
        "      _image = rgb2gray(_image / 255)\n",
        "  else:\n",
        "      _image = _image / 255\n",
        "  _image = resize(_image, IMAGE_SIZE)\n",
        "  return _image\n",
        "\n",
        "# TODO(Noah): Reimplement the code that sets up SH_RHD.\n",
        "gcs_path = 'data' if IN_COLAB else '../SH_RHD'\n",
        "train_list = os.listdir(os.path.join(gcs_path, \"training/color\"))\n",
        "eval_list = os.listdir(os.path.join(gcs_path, \"evaluation/color\"))\n",
        "\n",
        "# numpy \"buckets\" that we will use to load things in.\n",
        "x_train = np.zeros( (32, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) )\n",
        "y_train = np.zeros( (32, 21, 3) )\n",
        "x_test = np.zeros( (32, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) ) \n",
        "y_test = np.zeros( (32, 21, 3) )\n",
        "TRAIN_IMAGES = (len(train_list) // 32) * 32\n",
        "TEST_IMAGES = (len(eval_list) // 32) * 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3xZXThyyVta"
      },
      "source": [
        "# TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "mpOZpsk5rNev",
        "outputId": "bb019780-4cfe-4d57-c081-e00a4db6edbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss for pred of all zeros 0.0\n",
            "Loss for pred of all ones 1.0\n"
          ]
        }
      ],
      "source": [
        "class StupidSimpleLossMetric():\n",
        "    def __init__(self):\n",
        "        self.losses = [] # empty python array \n",
        "    def __call__(self, loss):\n",
        "        self.losses.append(loss)\n",
        "    def result(self):\n",
        "        return sum(self.losses) / len(self.losses)\n",
        "    def reset_states(self):\n",
        "        self.losses = []\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # defaults should work just fine\n",
        "train_loss = StupidSimpleLossMetric()\n",
        "test_loss = StupidSimpleLossMetric()\n",
        "\n",
        "# Loss function unit test\n",
        "input = tf.zeros([1, 21,3])  # mock pred of all zeros\n",
        "label = np.expand_dims(y_train[0], axis=0)\n",
        "loss = loss_fn(input, label) \n",
        "print('Loss for pred of all zeros', loss.numpy())\n",
        "#loss2 = loss_fn(label, label)\n",
        "#print('Loss for perfect prediction', loss2.numpy())\n",
        "input2 = tf.ones([1, 21, 3])\n",
        "loss3 = loss_fn(input2, label)\n",
        "print('Loss for pred of all ones', loss3.numpy())\n",
        "\n",
        "@tf.function\n",
        "def train_step(input, gt):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(input)\n",
        "        #loss = loss_func(predictions, segmentation_masks)\n",
        "        #loss = np.dot(tf.reshape(segmentation_masks, [102400], tf.reshape(predictions, [102400])\n",
        "        loss = loss_fn(predictions, gt)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "    #train_accuracy(labels, predictions)\n",
        "  \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  return loss_fn(predictions, labels)\n",
        "  #test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYZawQmCPIsf"
      },
      "outputs": [],
      "source": [
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "def cstr(str): # cyan string\n",
        "    return bcolors.OKCYAN + str + bcolors.ENDC\n",
        "\n",
        "checkpoint_path = \"checkpoints/\" if IN_COLAB else \"../checkpoints/\"\n",
        "!mkdir $checkpoint_path\n",
        "\n",
        "last_checkpoint = 5\n",
        "if (last_checkpoint > -1):\n",
        "  file_path = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(last_checkpoint))\n",
        "  model.load_weights(file_path)\n",
        "  print(cstr(\"Loaded weights from {}\".format(file_path)))\n",
        "\n",
        "EPOCHS = 10 # sure...\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  print(\"Begin epoch\", epoch)\n",
        "  start = time.time()\n",
        "  train_loss.reset_states()\n",
        "  #train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  #test_accuracy.reset_states()\n",
        "  \n",
        "  for i in range(TRAIN_IMAGES // 32):\n",
        "    for j in range(32):\n",
        "      train_image = download_image(os.path.join(gcs_path, 'training/color', train_list[j + i * 32]))\n",
        "      x_train[j,:,:,:] = train_image\n",
        "     \n",
        "    # TODO(Data Team): Load in the annotations.\n",
        "    x_train = x_train.astype('float32')\n",
        "    y_train = y_train.astype('float32')\n",
        "\n",
        "    loss = train_step(x_train, y_train)\n",
        "    train_loss(loss.numpy())\n",
        "\n",
        "  for i in range(TEST_IMAGES // 32):\n",
        "    for j in range(32):\n",
        "      eval_image = download_image(os.path.join(gcs_path, 'evaluation/color', eval_list[j + i * 32]))\n",
        "      x_test[j,:,:,:] = eval_image\n",
        "    x_test = x_test.astype('float32')\n",
        "    y_test = y_test.astype('float32')\n",
        "\n",
        "    loss_test = test_step(x_test, y_test)\n",
        "    test_loss(loss.numpy())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch}, '\n",
        "    f'Time {end-start} s'\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "  )\n",
        "\n",
        "  # Save the model parameters\n",
        "  if (epoch % 5 == 0):\n",
        "\n",
        "    checkpoint_filepath = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(epoch))\n",
        "    model.save_weights(checkpoint_filepath)\n",
        "    print(cstr(\"Saved weights to {}\".format(checkpoint_filepath)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FGNffUKbxtVJ"
      ],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "HandTracking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
