{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SETUP CODE #########\n",
    "IN_COLAB = False\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, MaxPool2D\n",
    "from tensorflow.keras import Model\n",
    "import random\n",
    "from qmindcolors import cstr\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "#NOTE: Good resource. -> https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "import cv2 # opencv, for image resizing.\n",
    "!pip install chumpy \n",
    "# NOTE(Noah): Stole this function from Stackoverflow :)\n",
    "def rgb2gray(rgb):\n",
    "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=2)\n",
    "def resize(img, size):\n",
    "    return cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(path):\n",
    "  image = imageio.imread(path)\n",
    "  _image = image.astype('float32')\n",
    "  if GRAYSCALE:\n",
    "      _image = rgb2gray(_image / 255)\n",
    "  else:\n",
    "      _image = _image / 255\n",
    "  _image = resize(_image, IMAGE_SIZE)\n",
    "  return _image\n",
    "\n",
    "gcs_path = os.path.join(\"..\", \"SH_RHD\")\n",
    "train_list = os.listdir(os.path.join(gcs_path, \"training/color\"))\n",
    "eval_list = os.listdir(os.path.join(gcs_path, \"evaluation/color\"))\n",
    "\n",
    "# Setup some params.\n",
    "IMAGE_SIZE = 224\n",
    "GRAYSCALE = False\n",
    "IMAGE_CHANNELS = 1 if GRAYSCALE else 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Numpy \"buckets\" that we will use to load things in.\n",
    "x_train = np.zeros((BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "x_test = np.zeros((BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_train_path = os.path.join(\"data\", \"anno\", \"anno_training.pickle\") if IN_COLAB else \\\n",
    "    os.path.join(\"..\", \"RHD_small\", \"training\", \"anno_training.pickle\")\n",
    "anno_eval_path = os.path.join(\"data\", \"anno\", \"anno_evaluation.pickle\") if IN_COLAB else \\\n",
    "    os.path.join(\"..\", \"RHD_small\", \"evaluation\", \"anno_evaluation.pickle\")\n",
    "\n",
    "# NOTE: We note that the numbers 41258 and 2728 were retrieved directly from\n",
    "# https://lmb.informatik.uni-freiburg.de/resources/datasets/RenderedHandposeDataset.en.html\n",
    "TRAIN_TOTAL_COUNT = 41258\n",
    "EVALUATION_TOTAL_COUNT = 2728\n",
    "\n",
    "y_train = np.zeros((TRAIN_TOTAL_COUNT, 21, 3))\n",
    "y_test = np.zeros((EVALUATION_TOTAL_COUNT, 21, 3))\n",
    "\n",
    "def load_anno(path, y):\n",
    "  anno_all = []\n",
    "  count = 0\n",
    "  with open(path, 'rb') as f:\n",
    "    anno_all = pickle.load(f)\n",
    "  for key, value in anno_all.items():\n",
    "    kp_visible = (value['uv_vis'][:, 2] == 1)\n",
    "    case1 = np.sum(kp_visible[0:21])\n",
    "    case2 = np.sum(kp_visible[21:])\n",
    "    leftHand = case1 > 0\n",
    "    # NOTE: We note here that we are not checking if this training or evaluation example is valid.\n",
    "    # i.e. we want to densely store the annotations.\n",
    "    if(not leftHand):\n",
    "        y[count, :, :] = value['xyz'][21:42]\n",
    "    else: \n",
    "        y[count, :, :] = value['xyz'][:21]\n",
    "    count += 1\n",
    "\n",
    "print(\"Loading in training annotations\")\n",
    "time_start = time.time()\n",
    "load_anno(anno_train_path, y_train)\n",
    "time_end = time.time()\n",
    "print(cstr(\"Training annotations loaded in {} s\".format(time_end - time_start)))\n",
    "print(\"Loading in evaluation annotations\")\n",
    "time_start = time.time()\n",
    "load_anno(anno_eval_path, y_test)\n",
    "time_end = time.time()\n",
    "print(cstr(\"Evaluation annotations loaded in {} s\".format(time_end - time_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANO_DIR = os.path.join(\"data\", \"mano_v1_2\") if IN_COLAB else os.path.join(\"..\", \"mano_v1_2\")\n",
    "from mobilehand import MAKE_MOBILE_HAND\n",
    "from mobilehand_lfuncs import LOSS_3D\n",
    "MOBILE_HAND = MAKE_MOBILE_HAND(IMAGE_SIZE, IMAGE_CHANNELS, BATCH_SIZE, MANO_DIR)\n",
    "model = MOBILE_HAND\n",
    "\n",
    "### MODEL FORWARD PASS TEST ###\n",
    "input_test = tf.random.uniform(shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "input_test = tf.cast(input_test, tf.float32)\n",
    "output_test = MOBILE_HAND(input_test)\n",
    "print(cstr(\"output_test =\"), output_test)\n",
    "### MODEL FORWARD PASS TEST ###\n",
    "\n",
    "from mobilehand_lfuncs import LOSS\n",
    "from mano_layer import MANO_Model\n",
    "_mpi_model = MANO_Model(MANO_DIR)\n",
    "# TODO(Noah): Expose U and L directly on our mobilehand implementation.\n",
    "U = _mpi_model.U\n",
    "L = _mpi_model.L\n",
    "loss_fn = lambda beta, pose, L, U, pred, gt : LOSS(beta, pose, L, U, pred, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidSimpleLossMetric():\n",
    "    def __init__(self):\n",
    "        self.losses = [] # empty python array \n",
    "    def __call__(self, loss):\n",
    "        self.losses.append(loss)\n",
    "    def result(self):\n",
    "        return sum(self.losses) / len(self.losses)\n",
    "    def reset_states(self):\n",
    "        self.losses = []\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # defaults should work just fine\n",
    "train_loss = StupidSimpleLossMetric()\n",
    "test_loss = StupidSimpleLossMetric()\n",
    "\n",
    "@tf.function\n",
    "def train_step(input, gt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        beta, pose, mesh, keypoints = model(input)\n",
    "        #loss = loss_func(predictions, segmentation_masks)\n",
    "        #loss = np.dot(tf.reshape(segmentation_masks, [102400], tf.reshape(predictions, [102400])\n",
    "        #loss = loss_fn(keypoints, gt)\n",
    "        loss = loss_fn(beta, pose, L, U, keypoints, gt)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "    #train_accuracy(labels, predictions)\n",
    "  \n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  beta, pose, mesh, keypoints = model(images, training=False)\n",
    "  return loss_fn(beta, pose, L, U, keypoints, labels)\n",
    "  #test_accuracy(labels, predictions)\n",
    "\n",
    "checkpoint_path = os.path.join(\"data\", \"checkpoints\") if IN_COLAB else os.path.join(\"..\", \"checkpoints/\")\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from render_ckpt import render_checkpoint_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $checkpoint_path\n",
    "\n",
    "last_checkpoint = -1\n",
    "if (last_checkpoint > -1):\n",
    "  file_path = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(last_checkpoint))\n",
    "  model.load_weights(file_path)\n",
    "  print(cstr(\"Loaded weights from {}\".format(file_path)))\n",
    "\n",
    "# load the crap\n",
    "y = np.zeros([BATCH_SIZE, 21, 3], dtype=np.float32)\n",
    "for j in range(BATCH_SIZE):\n",
    "  filename = train_list[3]\n",
    "  train_image = download_image(os.path.join(gcs_path, \"training\", \"color\", filename))\n",
    "  x_train[j,:,:,:] = train_image\n",
    "  y_index = int(filename[0:5])\n",
    "  y[j, :, :] = y_train[y_index]\n",
    "\n",
    "EPOCHS = 10 # sure...\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  print(\"Begin epoch\", epoch)\n",
    "  start = time.time()\n",
    "  train_loss.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  \n",
    "  x_train = x_train.astype('float32')\n",
    "  loss = train_step(x_train, y)\n",
    "  train_loss(loss.numpy())\n",
    " \n",
    "  '''\n",
    "  for i in range(1):\n",
    "    for j in range(BATCH_SIZE):\n",
    "      filename = eval_list[j + i * BATCH_SIZE]\n",
    "      eval_image = download_image(os.path.join(gcs_path, \"evaluation\", \"color\", filename))\n",
    "      x_test[j,:,:,:] = eval_image\n",
    "      y_index = int(filename[0:5])\n",
    "      y[j, :, :] = y_test[y_index]\n",
    "    x_test = x_test.astype('float32')\n",
    "    loss_test = test_step(x_test, y)\n",
    "    test_loss(loss.numpy())\n",
    "  '''\n",
    "\n",
    "  end = time.time()\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch}, '\n",
    "    f'Time {end-start} s'\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    #f'Test Loss: {test_loss.result()}, '\n",
    "  )\n",
    "\n",
    "  # Save the model parameters\n",
    "  #if (epoch % 5 == 0) or (epoch == EPOCHS - 1):\n",
    "  checkpoint_filepath = os.path.join(checkpoint_path, \"cp-{:04d}.ckpt\".format(epoch))\n",
    "  model.save_weights(checkpoint_filepath)\n",
    "  print(cstr(\"Saved weights to {}\".format(checkpoint_filepath)))\n",
    "\n",
    "  if not IN_COLAB:\n",
    "    # Run the model on image 19 of the evaluation images.\n",
    "    test_img = 26\n",
    "    eval_image = download_image(os.path.join(gcs_path, \"training\", \"color\", \"000{}.png\".format(test_img)))\n",
    "    eval_image = eval_image.astype('float32')\n",
    "    render_checkpoint_image(checkpoint_path, epoch, model, eval_image, y_train[test_img])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92e3dde21320b21078bf5b8c27013c99b8378d97a0c50fdf82b9dbd22849a6e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
